{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2af5377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pylot as plt\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddc78a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('training_data/eurusd_final_dataset.csv')\n",
    "\n",
    "# I am dropping because I don't want to use these features in the model currently\n",
    "X = data.drop(['label', 'Date_Time', 'hour', 'dayofweek', 'mins_into_m15', 'frac_into_m15'], axis=1)\n",
    "y = data['label']\n",
    "\n",
    "# Standardize\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, stratify=y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52ce6f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "3837/3837 [==============================] - 18s 4ms/step - loss: 1.3467 - accuracy: 0.5228 - val_loss: 1.1866 - val_accuracy: 0.5386\n",
      "Epoch 2/20\n",
      "3837/3837 [==============================] - 17s 4ms/step - loss: 1.3235 - accuracy: 0.5433 - val_loss: 1.1862 - val_accuracy: 0.5391\n",
      "Epoch 3/20\n",
      "3837/3837 [==============================] - 17s 4ms/step - loss: 1.3177 - accuracy: 0.5461 - val_loss: 1.1504 - val_accuracy: 0.5503\n",
      "Epoch 4/20\n",
      "3837/3837 [==============================] - 17s 5ms/step - loss: 1.3141 - accuracy: 0.5454 - val_loss: 1.1737 - val_accuracy: 0.5368\n",
      "Epoch 5/20\n",
      "3837/3837 [==============================] - 17s 4ms/step - loss: 1.3116 - accuracy: 0.5467 - val_loss: 1.1710 - val_accuracy: 0.5512\n",
      "Epoch 6/20\n",
      "3837/3837 [==============================] - 17s 4ms/step - loss: 1.3090 - accuracy: 0.5458 - val_loss: 1.1620 - val_accuracy: 0.5509\n",
      "Epoch 7/20\n",
      "3837/3837 [==============================] - 17s 5ms/step - loss: 1.3082 - accuracy: 0.5461 - val_loss: 1.1455 - val_accuracy: 0.5568\n",
      "Epoch 8/20\n",
      "3837/3837 [==============================] - 18s 5ms/step - loss: 1.3063 - accuracy: 0.5448 - val_loss: 1.1935 - val_accuracy: 0.5386\n",
      "Epoch 9/20\n",
      "3837/3837 [==============================] - 17s 5ms/step - loss: 1.3027 - accuracy: 0.5426 - val_loss: 1.1680 - val_accuracy: 0.5435\n",
      "Epoch 10/20\n",
      "3837/3837 [==============================] - 17s 5ms/step - loss: 1.3033 - accuracy: 0.5433 - val_loss: 1.1664 - val_accuracy: 0.5440\n",
      "Epoch 11/20\n",
      "3837/3837 [==============================] - 17s 4ms/step - loss: 1.3001 - accuracy: 0.5415 - val_loss: 1.1754 - val_accuracy: 0.5478\n",
      "Epoch 12/20\n",
      "3837/3837 [==============================] - 17s 5ms/step - loss: 1.2990 - accuracy: 0.5449 - val_loss: 1.1609 - val_accuracy: 0.5461\n",
      "Epoch 13/20\n",
      "3837/3837 [==============================] - 17s 4ms/step - loss: 1.2997 - accuracy: 0.5423 - val_loss: 1.1723 - val_accuracy: 0.5427\n",
      "Epoch 14/20\n",
      "3837/3837 [==============================] - 17s 5ms/step - loss: 1.2990 - accuracy: 0.5429 - val_loss: 1.1685 - val_accuracy: 0.5487\n",
      "Epoch 15/20\n",
      "3837/3837 [==============================] - 18s 5ms/step - loss: 1.2960 - accuracy: 0.5423 - val_loss: 1.1501 - val_accuracy: 0.5581\n",
      "Epoch 16/20\n",
      "3837/3837 [==============================] - 17s 5ms/step - loss: 1.2961 - accuracy: 0.5398 - val_loss: 1.1749 - val_accuracy: 0.5542\n",
      "Epoch 17/20\n",
      "3837/3837 [==============================] - 17s 4ms/step - loss: 1.2957 - accuracy: 0.5408 - val_loss: 1.1611 - val_accuracy: 0.5448\n",
      "Epoch 18/20\n",
      "3837/3837 [==============================] - 18s 5ms/step - loss: 1.2931 - accuracy: 0.5396 - val_loss: 1.1896 - val_accuracy: 0.5306\n",
      "Epoch 19/20\n",
      "3837/3837 [==============================] - 17s 5ms/step - loss: 1.2943 - accuracy: 0.5409 - val_loss: 1.1887 - val_accuracy: 0.5298\n",
      "Epoch 20/20\n",
      "3837/3837 [==============================] - 18s 5ms/step - loss: 1.2922 - accuracy: 0.5376 - val_loss: 1.1187 - val_accuracy: 0.5610\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to categorical\n",
    "y_train_cat = to_categorical(y_train, num_classes=5)\n",
    "y_test_cat = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.2),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(5, activation='softmax')\n",
    "])\n",
    "\n",
    "# Use the integer version of the labels here\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "# Convert to a dict if needed\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, y_train_cat, class_weight=class_weights, epochs=20, batch_size=32, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d027be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1066/1066 [==============================] - 3s 3ms/step\n",
      "Keras Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.75      0.75     16072\n",
      "           1       0.50      0.40      0.44     12110\n",
      "           2       0.26      0.33      0.29      3738\n",
      "           3       0.16      0.31      0.21      1243\n",
      "           4       0.24      0.28      0.26       941\n",
      "\n",
      "    accuracy                           0.55     34104\n",
      "   macro avg       0.38      0.41      0.39     34104\n",
      "weighted avg       0.57      0.55      0.56     34104\n",
      "\n",
      "Confusion Matrix:\n",
      "Class 0 — Precision: 0.75, Recall: 0.75, F1: 0.75\n",
      "Class 1 — Precision: 0.50, Recall: 0.40, F1: 0.44\n",
      "Class 2 — Precision: 0.26, Recall: 0.33, F1: 0.29\n",
      "Class 3 — Precision: 0.16, Recall: 0.31, F1: 0.21\n",
      "Class 4 — Precision: 0.24, Recall: 0.28, F1: 0.26\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Metrics\n",
    "print(\"Keras Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "#sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "#plt.xlabel(\"Predicted\")\n",
    "#plt.ylabel(\"True\")\n",
    "#plt.show()\n",
    "\n",
    "# Per-class Precision/Recall/F1\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "for i in range(5):\n",
    "    print(f\"Class {i} — Precision: {prec[i]:.2f}, Recall: {rec[i]:.2f}, F1: {f1[i]:.2f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a575ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulated trade logic example: TP = +2, SL = -1 per class prediction\n",
    "profit_rules = {0: 2, 1: -1, 2: 2, 3: -1, 4: 0}\n",
    "\n",
    "# Assume true class is the correct \"direction\" — reward if prediction matches\n",
    "profits = [profit_rules[p] if p == t else -1 for p, t in zip(y_pred, y_test)]\n",
    "total_profit = sum(profits)\n",
    "\n",
    "print(f\"Simulated Profit: {total_profit}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quant-trading",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
